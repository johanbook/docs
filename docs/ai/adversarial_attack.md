# Adversarial attack

An **adversarial attack** is where one attempts to fool an AI model by making
small changes in the input data. This can allow attackers to create media (such
as songs, photos and videos) such that they are interpreted as something
completely different to what humans would. A song could be interpreted as voice
commands.
